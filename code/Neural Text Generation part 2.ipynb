{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View alocated memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7275,
     "status": "ok",
     "timestamp": 1536040671962,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "izARBAXRv4CL",
    "outputId": "f791dd84-8a87-45b4-dff3-6ff54fc3ad43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gputil in /usr/local/lib/python3.6/dist-packages (1.3.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
      "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
      "Gen RAM Free: 10.5 GB  | Proc size: 3.3 GB\n",
      "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5WcxROPC0Im-"
   },
   "source": [
    "## Import Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 343
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2720,
     "status": "ok",
     "timestamp": 1536040678116,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "6RXWjj8q0QyD",
    "outputId": "3f9d4760-feed-496a-d66c-b53be97f4946"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.6.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim\n",
    "import gensim\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '../data'# data directory containing raw texts\n",
    "save_dir = '../out' # directory to store trained NN models\n",
    "seq_length = 30 # sequence length\n",
    "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "sequences_step = 1 #step to create sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1536040683643,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "Oi288NCm0Wzi",
    "outputId": "e48b9727-590d-4e93-f285-c2bec0cad290"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['203.txt',\n",
       " '103.txt',\n",
       " '209.txt',\n",
       " '403.txt',\n",
       " '107.txt',\n",
       " '407.txt',\n",
       " '202.txt',\n",
       " '301.txt',\n",
       " '111.txt',\n",
       " '101.txt']"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"../data/\"\n",
    "file_list = os.listdir( path )\n",
    "\n",
    "remove_files = ['input.txt','LICENSE']\n",
    "for r_files in remove_files:\n",
    "    file_list.remove(r_files)\n",
    "\n",
    "file_list = file_list[:10]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 547
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14386,
     "status": "ok",
     "timestamp": 1536040700836,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "znwzv5hV0nUa",
    "outputId": "3850888c-170e-488b-f9f0-39ed0ea7471a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.12)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.5)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.3.1)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.25.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.8.24)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "Requirement already satisfied: fr_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz#egg=fr_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
      "    /usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! pip install spacy\n",
    "#import spacy, and french model\n",
    "import spacy\n",
    "! python -m spacy download fr\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NWLvYEc31pOG"
   },
   "outputs": [],
   "source": [
    "#initiate sentences and labels lists\n",
    "sentences = []\n",
    "sentences_label = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_sentences** function read a document and return a tokenize list of the sentences of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KeKNMfgp1vFn"
   },
   "outputs": [],
   "source": [
    "#create sentences function:\n",
    "def create_sentences(doc):\n",
    "    ponctuation = [\".\",\"?\",\"!\",\":\",\"…\"]\n",
    "    sentences = []\n",
    "    sent = []\n",
    "    for word in doc:\n",
    "        if word.text not in ponctuation:\n",
    "            if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "                sent.append(word.text.lower())\n",
    "        else:\n",
    "            sent.append(word.text.lower())\n",
    "            if len(sent) > 1:\n",
    "                sentences.append(sent)\n",
    "            sent=[]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all documents to list of tockens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2h6VTEsg1yRv"
   },
   "outputs": [],
   "source": [
    "#create sentences from files\n",
    "for file_name in file_list:\n",
    "    #read data\n",
    "    input_file = os.path.join(data_dir, file_name)\n",
    "    \n",
    "    with codecs.open(input_file, \"r\", encoding='UTF-8') as f:\n",
    "        data = f.read()\n",
    "        \n",
    "    #create sentences\n",
    "    doc = nlp(data)\n",
    "    sents = create_sentences(doc)\n",
    "    sentences = sentences + sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—', 'non', ',', 'celui-là', 'n’', 'y', 'parvient', 'pas', 'non', 'plus', '!']"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—', 'tu', 'sais', 'ce', 'que', 'c’', 'est', '?']"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(sentences)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2442"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iu3SH-6c1_9F"
   },
   "outputs": [],
   "source": [
    "#create labels\n",
    "for i in range(np.array(sentences).shape[0]):\n",
    "    sentences_label.append(\"ID\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ID0', 'ID1', 'ID2', 'ID3', 'ID4', 'ID5', 'ID6', 'ID7', 'ID8', 'ID9']"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 853,
     "status": "ok",
     "timestamp": 1536042557676,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "IA83D2HW18Zd",
    "outputId": "a2dc5753-c464-4773-cf28-7a844f82579e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 10.4 GB  | Proc size: 3.6 GB\n",
      "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t6TnqFbg2513"
   },
   "source": [
    "## Train doc2vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "x-IN88Rj2C2t"
   },
   "outputs": [],
   "source": [
    "#class LabeledLineSentence(object):\n",
    "#    def __init__(self, doc_list, labels_list):\n",
    "#        self.labels_list = labels_list\n",
    "#        self.doc_list = doc_list\n",
    "#    def __iter__(self):\n",
    "#        for idx, doc in enumerate(self.doc_list):\n",
    "#            yield gensim.models.doc2vec.TaggedDocument(doc,[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LabeledLineSentence** is a generator function which Replaces “sentence as a list of words” from gensim.models.word2vec.Word2Vec."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generator function** is used for large data.it process a single instance of a data, return it and then process the next instance of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LabeledLineSentence(doc_list,labels_list):\n",
    "        for idx, doc in enumerate(doc_list):\n",
    "            #print(doc)\n",
    "            #print(\"###\" + str(labels_list[idx]))\n",
    "            yield gensim.models.doc2vec.TaggedDocument(doc,[labels_list[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a own word imbading model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uDEyYPNu2J21"
   },
   "outputs": [],
   "source": [
    "def train_doc2vec_model(data, docLabels, size=300, sample=0.000001, dm=0, hs=1, window=10, min_count=0, workers=8,alpha=0.024, min_alpha=0.024, epoch=15, save_file='../out/doc2vec.w2v') :\n",
    "    startime = time.time()\n",
    "    \n",
    "    print(\"{0} articles loaded for model\".format(len(data)))\n",
    "\n",
    "    it = LabeledLineSentence(data, docLabels)\n",
    "\n",
    "    model = gensim.models.Doc2Vec(vector_size=size, sample=sample, dm=dm, window=window, min_count=min_count, workers=workers,alpha=alpha, min_alpha=min_alpha, hs=hs) # use fixed learning rate\n",
    "    model.build_vocab(it)\n",
    "    for epoch in range(epoch):\n",
    "        print(\"Training epoch {}\".format(epoch + 1))\n",
    "        model.train(it,total_examples=model.corpus_count,epochs=model.epochs)\n",
    "        # model.alpha -= 0.002 # decrease the learning rate\n",
    "        # model.min_alpha = model.alpha # fix the learning rate, no decay\n",
    "        \n",
    "    #saving the created model\n",
    "    model.save(os.path.join(save_file))\n",
    "    print('model saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 34881,
     "status": "ok",
     "timestamp": 1536042699641,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "nMoCkWTO3QVb",
    "outputId": "e07e6086-fa43-4c7f-cb1e-2a1398e6de9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2442 articles loaded for model\n",
      "Training epoch 1\n",
      "Training epoch 2\n",
      "Training epoch 3\n",
      "Training epoch 4\n",
      "Training epoch 5\n",
      "Training epoch 6\n",
      "Training epoch 7\n",
      "Training epoch 8\n",
      "Training epoch 9\n",
      "Training epoch 10\n",
      "Training epoch 11\n",
      "Training epoch 12\n",
      "Training epoch 13\n",
      "Training epoch 14\n",
      "Training epoch 15\n",
      "Training epoch 16\n",
      "Training epoch 17\n",
      "Training epoch 18\n",
      "Training epoch 19\n",
      "Training epoch 20\n",
      "model saved\n"
     ]
    }
   ],
   "source": [
    "train_doc2vec_model(sentences, sentences_label, size=500,sample=0.0,alpha=0.025, min_alpha=0.001, min_count=0, window=10, epoch=20, dm=0, hs=1, save_file='../out/doc2vec.w2v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TOzJmUtER_LP"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lJxkO0sr42Bj"
   },
   "source": [
    "## Create the Input Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As LSTM don't accept string or list of string. So represent the sentence with a list of int. len of the list is 500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1998820,
     "status": "ok",
     "timestamp": 1536044814627,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "HDo8yOlJ437_",
    "outputId": "08b12623-062c-409d-f9fb-a610db90d054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence 0 : ['—', 'tu', 'sais', 'ce', 'que', 'c’', 'est', '?']\n",
      "***\n",
      "sentence 500 : ['le', 'monstre', 'se', 'retourne', '.']\n",
      "***\n",
      "sentence 1000 : ['cependant', ',', 'les', 'battements', 'sourds', 'qui', 's’', 'en', 'échappent', 'sont', 'apaisants', '.']\n",
      "***\n",
      "sentence 1500 : ['désormais', ',', 'ils', 'se', 'laissent', 'guider', 'par', 'les', 'autres', 'apprentis', 'vers', 'l’', 'endroit', 'où', 'les', 'attend', 'lothar', ',', 'en', 'faisant', 'très', 'attention', 'à', 'ne', 'pas', 'les', 'perdre', 'de', 'vue', '.']\n",
      "***\n",
      "sentence 2000 : ['le', 'jeune', 'homme', 'leur', 'lance', 'un', 'ultime', 'regard', 'sans', 'réel', 'espoir', ',', 'mais', 'ils', 'ne', 'desserrent', 'même', 'pas', 'les', 'dents', '.']\n",
      "***\n"
     ]
    }
   ],
   "source": [
    "#import library\n",
    "from six.moves import cPickle\n",
    "\n",
    "#load the model\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('../out/doc2vec.w2v')\n",
    "\n",
    "sentences_vector=[]\n",
    "\n",
    "t = 500\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    if i % t == 0:\n",
    "        print(\"sentence\", i, \":\", sentences[i])\n",
    "        print(\"***\")\n",
    "        #print(d2v_model.infer_vector(sentences[i], alpha=0.001, min_alpha=0.001, steps=10000))\n",
    "        #print(len(d2v_model.infer_vector(sentences[i], alpha=0.001, min_alpha=0.001, steps=10000)))\n",
    "    sent = sentences[i]\n",
    "    sentences_vector.append(d2v_model.infer_vector(sent, alpha=0.001, min_alpha=0.001, steps=10000))\n",
    "    \n",
    "#save the sentences_vector\n",
    "sentences_vector_file = os.path.join(save_dir, \"sentences_vector_500_a001_ma001_s10000.pkl\")\n",
    "with open(os.path.join(sentences_vector_file), 'wb') as f:\n",
    "    cPickle.dump((sentences_vector), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1320,
     "status": "ok",
     "timestamp": 1536044815975,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "6r4ukVtk5Kee",
    "outputId": "4b1bae3c-8ab4-4181-f228-eefc57878a29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 10.4 GB  | Proc size: 3.6 GB\n",
      "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1013,
     "status": "ok",
     "timestamp": 1536045112450,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "bW-Q08kvaw3x",
    "outputId": "639321b3-5f8f-4fcd-b3a5-3c975323c65a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—', 'tu', 'sais', 'ce', 'que', 'c’', 'est', '?']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-3.72007315e-04,  7.68059108e-04,  2.41480710e-04, -3.96743271e-04,\n",
       "        1.61228643e-04, -6.11503085e-04,  1.72399770e-04, -3.11214040e-04,\n",
       "        6.24620763e-04, -5.36825624e-04,  8.25450872e-04, -9.68994864e-04,\n",
       "        7.31707958e-04,  8.62358778e-04, -3.35665216e-04, -6.67530519e-04,\n",
       "        6.09208764e-05,  3.04898480e-04, -2.53713195e-04,  4.45768055e-05,\n",
       "        5.78516163e-04, -4.19058459e-04,  7.24629441e-04, -5.27163269e-04,\n",
       "        7.71471416e-04,  3.85969586e-04,  9.03094246e-04, -1.00288547e-04,\n",
       "       -8.42830559e-05, -7.94795575e-04, -1.98369657e-04, -1.54940990e-05,\n",
       "       -2.70826888e-04,  2.46611075e-04, -5.62766509e-04, -7.38711678e-04,\n",
       "       -9.51848284e-04, -9.36580531e-04,  1.93576023e-04,  1.71097257e-04,\n",
       "        3.68148088e-04, -6.92102010e-04, -9.04273766e-04,  7.93280080e-04,\n",
       "       -7.72567582e-04, -6.48292422e-04,  1.14945178e-05, -4.87285870e-04,\n",
       "        3.74200434e-04,  7.07626110e-04, -6.34238706e-04, -8.73770987e-05,\n",
       "        8.37425468e-04, -6.47071865e-04,  3.29927600e-04, -3.50050279e-04,\n",
       "       -7.49902043e-04, -6.16984500e-04,  8.22629154e-05, -9.26844077e-04,\n",
       "       -3.56792327e-04, -7.67981401e-04, -7.44791934e-04,  4.53985267e-04,\n",
       "        3.92191811e-04, -5.15146530e-04,  3.48475442e-04, -6.74098905e-04,\n",
       "       -9.02221247e-04,  4.31147171e-04,  4.94136533e-04, -4.24429687e-04,\n",
       "        1.37113151e-04, -9.32496623e-04, -4.48979263e-04,  8.42093257e-04,\n",
       "        6.14308112e-04,  3.28884344e-04, -1.31449357e-04, -4.22159646e-04,\n",
       "        1.77368594e-04, -7.76766043e-04, -2.19323556e-04, -4.69677558e-04,\n",
       "       -8.98825470e-04,  5.76584716e-04,  4.29656240e-04,  7.42973876e-04,\n",
       "        1.35092661e-04,  4.92163235e-05, -2.45850155e-04, -8.11330043e-04,\n",
       "       -9.42712883e-04,  4.71857260e-04,  5.85265283e-04,  3.51439870e-04,\n",
       "       -7.69203762e-04,  6.36163109e-04, -3.44930158e-05, -7.51250249e-04,\n",
       "       -8.33773811e-04, -2.62629444e-04,  3.97090334e-04, -4.61522897e-04,\n",
       "        9.70194058e-04,  4.17633273e-04, -2.31596234e-04, -3.01258580e-04,\n",
       "        8.91340547e-04, -1.22810772e-04, -7.80529866e-04,  5.45803516e-04,\n",
       "        8.87393602e-04,  6.65506057e-04,  6.72574912e-04, -1.73818655e-04,\n",
       "       -8.98855447e-04,  1.77064343e-04,  8.30760633e-04,  1.65365185e-04,\n",
       "        7.84101721e-04,  2.79711938e-04, -7.81939947e-04,  1.24351092e-04,\n",
       "       -7.92981475e-04, -5.99030172e-04, -2.05290824e-04, -2.70323362e-04,\n",
       "        1.10800684e-04, -1.60337731e-04,  2.52875645e-04, -4.95274842e-04,\n",
       "       -3.52997769e-04, -9.54977237e-04, -1.37861338e-04,  3.86445536e-05,\n",
       "        3.96130577e-04,  5.15931577e-04,  9.12681207e-05, -2.19156893e-04,\n",
       "       -8.97303631e-04,  8.77791783e-04, -1.56234819e-05, -1.16114337e-04,\n",
       "       -9.25169385e-04,  6.85703708e-04,  8.37372150e-04, -4.00188670e-04,\n",
       "        2.09651364e-04,  1.49828862e-04, -1.01899350e-04,  8.44054623e-04,\n",
       "       -9.56733362e-04, -1.64219164e-04,  8.25922994e-04,  6.64072460e-04,\n",
       "       -3.94467876e-04, -9.92213958e-04, -1.74591492e-04,  8.96234880e-04,\n",
       "        8.40959779e-04, -8.52666504e-04,  5.40380366e-04, -7.62037758e-04,\n",
       "       -7.27442850e-04, -2.61729059e-04, -7.02025311e-04, -8.82725464e-04,\n",
       "       -8.92919488e-04,  4.22634948e-05,  7.12697161e-04,  2.49728677e-04,\n",
       "        5.54592232e-04,  1.88646911e-04, -9.60280449e-05,  7.31735025e-04,\n",
       "        7.85335651e-05,  8.51880934e-04,  4.42510936e-04,  7.47079030e-04,\n",
       "        4.66307480e-04,  5.95821766e-04,  1.54949710e-04, -2.85619317e-04,\n",
       "       -4.35936527e-04,  6.32098177e-04,  1.05593965e-04,  2.62765934e-05,\n",
       "       -3.58772057e-04, -1.32367713e-04,  8.66878137e-04, -9.95392795e-04,\n",
       "        3.42006068e-04,  4.83188604e-04,  5.54355393e-05,  7.59231480e-05,\n",
       "       -5.58582949e-04,  4.35070426e-04, -4.78674687e-04,  8.87741160e-04,\n",
       "       -9.86582832e-04,  5.82826906e-04, -3.68839983e-06,  4.11167421e-04,\n",
       "        6.34584168e-04,  7.92599400e-04, -3.77751945e-04,  6.90719578e-04,\n",
       "       -4.07275656e-04, -6.79976132e-04,  4.66452126e-04,  8.10945407e-04,\n",
       "       -9.42591694e-04,  4.28531610e-04, -2.63884838e-04, -7.55788875e-04,\n",
       "       -1.92680513e-04, -8.44581868e-04,  3.48142494e-04,  7.35212379e-05,\n",
       "       -9.97043331e-04,  1.88895414e-04,  8.54110403e-04,  7.98585766e-04,\n",
       "       -5.56042942e-04,  7.67044199e-04,  3.29677190e-04,  6.60046993e-04,\n",
       "       -5.58035623e-04, -8.54923739e-04,  1.00115270e-04,  1.27946230e-04,\n",
       "        2.32343707e-04, -6.37175224e-04, -8.98668892e-04, -9.82431811e-04,\n",
       "        5.30702760e-04,  4.86617064e-04,  3.41551233e-04,  7.90788850e-04,\n",
       "        1.26060273e-04, -8.74517951e-04, -5.20092086e-04, -1.99502669e-04,\n",
       "       -8.51497112e-04, -9.50755551e-04,  8.76108243e-04, -1.23594611e-04,\n",
       "        4.75668407e-04, -4.96541441e-04, -1.14802551e-05,  7.10953667e-04,\n",
       "        4.42546763e-04, -2.40897807e-05, -5.60732515e-05, -1.92851672e-04,\n",
       "        1.63985344e-04, -5.78637300e-05, -3.97650147e-04,  9.32024152e-04,\n",
       "       -1.99809961e-04,  3.16664577e-04, -9.77119664e-04, -1.63946097e-04,\n",
       "       -2.79586879e-04,  9.80273355e-04,  8.33671016e-04, -8.34914856e-04,\n",
       "        9.98379313e-04, -7.05879473e-04,  9.32419091e-04,  7.34102912e-04,\n",
       "       -4.37944953e-04,  7.67290985e-05,  1.38042626e-04,  5.59600194e-05,\n",
       "        8.66188901e-04, -6.93240872e-05,  9.76410403e-04, -2.86009599e-04,\n",
       "       -7.35853391e-04,  1.65663907e-04, -1.93136975e-06, -8.34151171e-04,\n",
       "       -9.56644129e-04,  7.47164595e-04,  5.29933430e-04, -9.99618554e-04,\n",
       "       -8.62984336e-04,  9.34655545e-04, -7.36825692e-04,  1.93894622e-04,\n",
       "       -6.65150292e-04,  3.58602352e-04, -7.25968566e-04,  5.97886974e-04,\n",
       "        3.28560534e-04,  6.95618917e-04,  3.31026473e-04, -3.82875616e-04,\n",
       "        5.99791412e-04, -1.23359481e-04, -8.77735962e-04,  7.92519364e-04,\n",
       "        9.25330736e-04, -4.07213724e-04, -6.03188062e-04, -2.22231989e-04,\n",
       "        7.06103456e-05, -7.55918561e-04,  2.56754196e-04, -5.77814120e-04,\n",
       "        5.50974277e-04, -1.97459769e-04,  8.42602283e-04, -9.11889365e-04,\n",
       "        3.83744540e-04,  8.71487369e-04,  5.87868853e-05, -5.88168099e-04,\n",
       "        8.88515962e-04, -1.39652446e-04, -7.18942756e-05, -1.17169337e-04,\n",
       "        1.10789966e-04,  2.90872104e-05,  5.02390249e-05,  5.76579710e-04,\n",
       "       -5.22943737e-04, -6.11558557e-04, -2.44184630e-04, -4.84182470e-04,\n",
       "        3.13507626e-04, -8.10777477e-04, -6.41338353e-04, -7.64906639e-04,\n",
       "       -9.52895207e-04,  9.36914468e-04,  9.17074271e-04, -8.66991235e-04,\n",
       "        9.03970562e-04,  4.85331402e-04, -1.42978979e-05,  1.48080380e-06,\n",
       "        8.60454340e-04, -7.19061529e-04, -7.35636801e-04, -9.90604633e-04,\n",
       "        7.67039834e-04, -4.78411763e-04,  6.88549364e-04,  8.05827614e-04,\n",
       "        5.84091584e-04,  9.48612404e-04,  8.50753684e-04, -6.84228959e-04,\n",
       "       -8.35004495e-04,  6.85278268e-04,  8.43237154e-04, -6.17858488e-04,\n",
       "        6.47224195e-04,  9.88611573e-05,  7.01449389e-05, -6.49041438e-04,\n",
       "        9.42123181e-04, -2.15894121e-04, -9.12585063e-04,  9.82160098e-04,\n",
       "       -2.79710308e-04,  6.18039863e-04,  5.08598518e-04, -2.19438807e-05,\n",
       "        3.92027287e-04, -8.37661792e-04,  1.19288627e-04, -1.57847680e-04,\n",
       "        6.57548153e-05,  6.64266176e-04,  8.63439403e-04, -7.49569503e-04,\n",
       "       -4.25924431e-04,  1.00189369e-04,  3.20858089e-04, -1.41544326e-04,\n",
       "        2.85859511e-04,  6.43563922e-04,  7.15060087e-05,  6.44627376e-04,\n",
       "        2.90818076e-04,  6.40959130e-04,  1.48038875e-04, -7.68951199e-04,\n",
       "        6.20943611e-04, -5.97254373e-04,  3.25655565e-04,  2.93945253e-04,\n",
       "        7.41239870e-04,  1.90408871e-04, -6.11437543e-04,  2.21396840e-04,\n",
       "        1.31097331e-04, -8.60353815e-04,  7.48700288e-04, -4.07040177e-04,\n",
       "        3.60690407e-04, -9.12229065e-04, -4.17892210e-04, -3.03761452e-04,\n",
       "        3.99573270e-04, -1.50101288e-04,  5.78656269e-04,  5.64444636e-04,\n",
       "        9.95901864e-05,  5.46416617e-04,  2.43608301e-04,  3.40881757e-04,\n",
       "        3.95858369e-04, -4.64088866e-04, -5.32616745e-04,  1.60721027e-06,\n",
       "        8.60854285e-04, -3.33090749e-04,  4.49997518e-04, -2.65786221e-04,\n",
       "        6.48400804e-04, -5.25734911e-04,  2.20401402e-04,  5.68418996e-04,\n",
       "        9.05733905e-04, -7.42484292e-04, -4.24568483e-04, -9.37914592e-04,\n",
       "       -9.64484178e-04,  5.39572851e-04,  5.74164558e-04,  8.57163512e-04,\n",
       "       -8.36982334e-04, -4.92098450e-04,  7.54868612e-04, -5.94240148e-04,\n",
       "       -8.55642720e-04,  7.76364934e-04,  1.22034755e-04, -6.25597721e-04,\n",
       "        3.54020565e-04, -5.12514787e-04, -9.08115704e-04, -6.95548020e-04,\n",
       "        3.95090639e-04, -3.30948416e-04,  6.53078314e-04, -1.30203582e-04,\n",
       "        9.86441621e-04, -3.62245250e-04, -1.33698763e-04,  1.90426828e-04,\n",
       "       -7.67799444e-04,  7.56931899e-04, -3.22312029e-04,  4.20500815e-04,\n",
       "       -4.95702436e-04,  2.36885739e-04, -8.06299911e-04, -6.55173440e-04,\n",
       "        1.05443425e-04, -4.66808997e-04, -5.43993548e-04,  1.85914003e-04,\n",
       "       -7.11481203e-04,  3.57665354e-04, -7.72527186e-04, -6.59084588e-04,\n",
       "       -8.57071311e-04, -2.57079955e-04, -4.55302070e-04, -5.97294304e-04,\n",
       "       -6.59200654e-04,  9.95680923e-04, -3.12028482e-04, -7.08010746e-04,\n",
       "       -7.84572389e-04, -7.53021217e-04,  2.23625975e-04, -6.44914166e-04,\n",
       "       -3.20961517e-05, -6.23545959e-04, -8.30991848e-05,  3.40275379e-04,\n",
       "       -9.62687773e-04,  6.81203033e-04,  8.11008329e-04, -1.95069530e-04,\n",
       "        4.21421631e-04,  1.56740367e-04,  2.70277698e-04,  5.82200184e-04,\n",
       "       -2.45494361e-04, -3.32025702e-05,  2.02008421e-04, -8.49885808e-04],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_vector[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider every 15 element from **sentences_vector** list as input X and 16th element as output Y.<br> Note that, each element in **sentences_vector** is a list of int with len of 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1190
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10079,
     "status": "ok",
     "timestamp": 1536045255396,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "KfyjzEk3bHYY",
    "outputId": "54510c50-90dd-458c-ea50-7367fa0ee88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new sequence:  0\n",
      "   1 th vector for this sequence. Sentence  ID0 (vector dim =  500 )\n",
      "   2 th vector for this sequence. Sentence  ID1 (vector dim =  500 )\n",
      "   3 th vector for this sequence. Sentence  ID2 (vector dim =  500 )\n",
      "   4 th vector for this sequence. Sentence  ID3 (vector dim =  500 )\n",
      "   5 th vector for this sequence. Sentence  ID4 (vector dim =  500 )\n",
      "   6 th vector for this sequence. Sentence  ID5 (vector dim =  500 )\n",
      "   7 th vector for this sequence. Sentence  ID6 (vector dim =  500 )\n",
      "   8 th vector for this sequence. Sentence  ID7 (vector dim =  500 )\n",
      "   9 th vector for this sequence. Sentence  ID8 (vector dim =  500 )\n",
      "   10 th vector for this sequence. Sentence  ID9 (vector dim =  500 )\n",
      "   11 th vector for this sequence. Sentence  ID10 (vector dim =  500 )\n",
      "   12 th vector for this sequence. Sentence  ID11 (vector dim =  500 )\n",
      "   13 th vector for this sequence. Sentence  ID12 (vector dim =  500 )\n",
      "   14 th vector for this sequence. Sentence  ID13 (vector dim =  500 )\n",
      "   15 th vector for this sequence. Sentence  ID14 (vector dim =  500 )\n",
      "  y vector for this sequence  ID15 : (vector dim =  500 )\n",
      "new sequence:  1000\n",
      "   1 th vector for this sequence. Sentence  ID1000 (vector dim =  500 )\n",
      "   2 th vector for this sequence. Sentence  ID1001 (vector dim =  500 )\n",
      "   3 th vector for this sequence. Sentence  ID1002 (vector dim =  500 )\n",
      "   4 th vector for this sequence. Sentence  ID1003 (vector dim =  500 )\n",
      "   5 th vector for this sequence. Sentence  ID1004 (vector dim =  500 )\n",
      "   6 th vector for this sequence. Sentence  ID1005 (vector dim =  500 )\n",
      "   7 th vector for this sequence. Sentence  ID1006 (vector dim =  500 )\n",
      "   8 th vector for this sequence. Sentence  ID1007 (vector dim =  500 )\n",
      "   9 th vector for this sequence. Sentence  ID1008 (vector dim =  500 )\n",
      "   10 th vector for this sequence. Sentence  ID1009 (vector dim =  500 )\n",
      "   11 th vector for this sequence. Sentence  ID1010 (vector dim =  500 )\n",
      "   12 th vector for this sequence. Sentence  ID1011 (vector dim =  500 )\n",
      "   13 th vector for this sequence. Sentence  ID1012 (vector dim =  500 )\n",
      "   14 th vector for this sequence. Sentence  ID1013 (vector dim =  500 )\n",
      "   15 th vector for this sequence. Sentence  ID1014 (vector dim =  500 )\n",
      "  y vector for this sequence  ID1015 : (vector dim =  500 )\n",
      "new sequence:  2000\n",
      "   1 th vector for this sequence. Sentence  ID2000 (vector dim =  500 )\n",
      "   2 th vector for this sequence. Sentence  ID2001 (vector dim =  500 )\n",
      "   3 th vector for this sequence. Sentence  ID2002 (vector dim =  500 )\n",
      "   4 th vector for this sequence. Sentence  ID2003 (vector dim =  500 )\n",
      "   5 th vector for this sequence. Sentence  ID2004 (vector dim =  500 )\n",
      "   6 th vector for this sequence. Sentence  ID2005 (vector dim =  500 )\n",
      "   7 th vector for this sequence. Sentence  ID2006 (vector dim =  500 )\n",
      "   8 th vector for this sequence. Sentence  ID2007 (vector dim =  500 )\n",
      "   9 th vector for this sequence. Sentence  ID2008 (vector dim =  500 )\n",
      "   10 th vector for this sequence. Sentence  ID2009 (vector dim =  500 )\n",
      "   11 th vector for this sequence. Sentence  ID2010 (vector dim =  500 )\n",
      "   12 th vector for this sequence. Sentence  ID2011 (vector dim =  500 )\n",
      "   13 th vector for this sequence. Sentence  ID2012 (vector dim =  500 )\n",
      "   14 th vector for this sequence. Sentence  ID2013 (vector dim =  500 )\n",
      "   15 th vector for this sequence. Sentence  ID2014 (vector dim =  500 )\n",
      "  y vector for this sequence  ID2015 : (vector dim =  500 )\n",
      "(2442, 15, 500) (2442, 500)\n"
     ]
    }
   ],
   "source": [
    "nb_sequenced_sentences = 15\n",
    "vector_dim = 500\n",
    "\n",
    "X_train = np.zeros((len(sentences), nb_sequenced_sentences, vector_dim), dtype=np.float)\n",
    "y_train = np.zeros((len(sentences), vector_dim), dtype=np.float)\n",
    "\n",
    "t = 1000\n",
    "for i in range(len(sentences_label)-nb_sequenced_sentences-1):\n",
    "    if i % t == 0: print(\"new sequence: \", i)\n",
    "    \n",
    "    for k in range(nb_sequenced_sentences):\n",
    "        sent = sentences_label[i+k]\n",
    "        vect = sentences_vector[i+k]\n",
    "        \n",
    "        if i % t == 0:\n",
    "            print(\"  \", k + 1 ,\"th vector for this sequence. Sentence \", sent, \"(vector dim = \", len(vect), \")\")\n",
    "            #print(vect[j])\n",
    "            #print(j)\n",
    "            \n",
    "        for j in range(len(vect)):\n",
    "            #print(vect[j])\n",
    "            X_train[i, k, j] = vect[j]\n",
    "    \n",
    "    senty = sentences_label[i+nb_sequenced_sentences]\n",
    "    vecty = sentences_vector[i+nb_sequenced_sentences]\n",
    "    if i % t == 0: print(\"  y vector for this sequence \", senty, \": (vector dim = \", len(vecty), \")\")\n",
    "    for j in range(len(vecty)):\n",
    "        y_train[i, j] = vecty[j]\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 809,
     "status": "ok",
     "timestamp": 1536045421518,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "84VFerwmbmL2",
    "outputId": "1fb5677a-6e90-420d-ff4a-3a7fbdd54953"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-7.79064256e-04,  5.56897896e-04,  3.71264643e-04,  6.99287164e-04,\n",
       "        7.11440283e-04,  6.45804219e-04,  8.68366100e-04, -1.90325620e-04,\n",
       "       -6.62198523e-04,  6.80964033e-04, -3.56519558e-05, -6.10794756e-04,\n",
       "       -8.95912584e-04, -2.32867838e-04, -2.81689718e-04,  9.55429350e-05,\n",
       "       -7.84405624e-04, -9.86512314e-05,  4.23429447e-04, -1.22950496e-05,\n",
       "        3.15491081e-04,  6.85536797e-05,  2.52309459e-04, -8.64669215e-04,\n",
       "       -3.95687879e-04, -1.16321113e-04, -1.83953307e-05,  4.15063434e-04,\n",
       "        9.60217381e-04,  9.32978874e-04, -5.95584803e-04,  3.56841454e-04,\n",
       "        1.21537734e-04,  1.91114959e-04,  9.69990215e-04,  1.36062416e-04,\n",
       "        2.95663427e-04,  2.75869941e-04,  9.07400390e-04,  5.46150666e-04,\n",
       "        6.41204068e-04, -1.59310977e-04,  2.68938573e-04,  3.12351942e-04,\n",
       "        5.07670804e-04, -5.42500311e-05,  2.60365341e-05, -4.15587449e-04,\n",
       "        9.43719933e-04,  1.89663246e-04, -7.57334987e-04,  1.26255167e-04,\n",
       "       -3.90451401e-04, -5.75399317e-04, -2.14928703e-04,  7.83482974e-04,\n",
       "        6.31953997e-04, -2.52537488e-04,  8.82514287e-04,  9.59325465e-04,\n",
       "       -6.82919868e-04, -6.50711765e-04, -7.23609643e-04,  5.71378565e-04,\n",
       "        4.90033563e-06,  1.09754292e-05,  4.50679974e-04, -2.43085422e-04,\n",
       "       -4.79663286e-05, -3.87325563e-04, -4.00275749e-05,  1.96282181e-05,\n",
       "        7.62265117e-04,  7.72035739e-04, -4.76720859e-04, -4.18219366e-04,\n",
       "       -6.90096349e-04,  1.75386478e-04, -9.41388309e-04,  1.10667024e-05,\n",
       "        1.10249632e-04, -6.32941374e-04, -1.22345620e-04, -4.39118070e-04,\n",
       "        5.99238148e-04, -9.93098714e-04, -6.19503320e-04,  6.04122179e-04,\n",
       "       -1.18053713e-05,  3.80509620e-04, -5.31934609e-04,  5.52873127e-04,\n",
       "        9.69897490e-04, -9.14639095e-04,  9.84908547e-04, -8.99138395e-04,\n",
       "       -6.22671214e-04, -8.20448797e-04, -8.61591194e-04, -3.20154504e-04,\n",
       "        7.88289297e-04,  6.61291066e-04, -5.16384491e-04, -5.10556391e-04,\n",
       "       -2.18525951e-04, -5.98905783e-04,  8.43669113e-04, -9.66246764e-04,\n",
       "       -8.77559709e-04,  7.59835530e-04,  1.45042810e-04,  5.49784105e-04,\n",
       "       -6.70037916e-05,  9.03956417e-04, -6.20892461e-05,  3.59859871e-04,\n",
       "        5.54488972e-04, -6.28090173e-04, -3.96155112e-04, -1.29092878e-04,\n",
       "       -8.26820178e-05,  3.15288111e-04, -4.45692800e-04,  6.56684162e-04,\n",
       "       -2.15186170e-04,  4.18265176e-04, -3.43394931e-04,  2.77875079e-04,\n",
       "        1.11431254e-04, -7.14062306e-04,  6.79683348e-04, -8.26315721e-04,\n",
       "       -8.22482107e-04, -7.74000480e-04, -4.01766360e-04, -8.04007577e-04,\n",
       "        5.06467419e-04,  9.08737129e-04,  8.01091723e-04,  9.98011441e-04,\n",
       "        8.95092613e-04,  1.93285945e-04, -3.64629377e-05, -6.43548701e-05,\n",
       "        9.60077683e-04, -1.48137042e-04, -1.91763960e-04,  2.15699562e-04,\n",
       "        9.04807705e-04, -7.14283669e-04,  7.19105592e-04, -4.96119377e-04,\n",
       "       -2.19586072e-04,  6.61174592e-04,  2.13663043e-05,  4.51875007e-04,\n",
       "        4.18069540e-04,  2.45104806e-04, -9.13036638e-04, -3.51500319e-04,\n",
       "        7.86526653e-04, -3.07501847e-04,  4.83940268e-04, -9.46257787e-04,\n",
       "       -6.89002103e-04, -5.33499173e-04,  7.85556331e-04, -7.16438051e-04,\n",
       "        6.33385207e-04, -3.74689203e-04,  8.59800261e-04,  7.86119315e-04,\n",
       "        4.84420132e-04, -6.97522075e-04,  9.56619682e-04, -2.49619392e-04,\n",
       "        9.77845048e-05,  2.22724469e-04,  1.38131918e-05, -2.47970893e-04,\n",
       "       -2.06506869e-04,  3.99534445e-04,  8.09293633e-05, -8.80914158e-04,\n",
       "        9.89090418e-04, -9.28530993e-04,  6.42069557e-04,  5.64623449e-04,\n",
       "       -5.93486242e-04, -3.60166130e-04,  8.70336022e-04,  6.37116376e-04,\n",
       "       -9.06336354e-04, -9.64846113e-04, -4.88522965e-05,  1.22668920e-04,\n",
       "       -2.12486440e-04,  2.05999371e-04,  8.39608663e-04, -2.15965301e-05,\n",
       "       -1.48416089e-04, -6.16140722e-04,  1.00609126e-04,  3.11695767e-04,\n",
       "       -3.76086857e-04, -2.10664322e-04, -4.77002061e-04, -4.33249050e-04,\n",
       "       -9.56217536e-06,  2.39752611e-04,  7.70742306e-04, -7.87216530e-04,\n",
       "       -9.63384053e-04,  7.18556927e-04, -3.19163155e-06, -1.18974633e-04,\n",
       "       -4.16200375e-04,  4.19988908e-04, -3.39660728e-05,  2.93084537e-04,\n",
       "        8.49943754e-05, -4.89365542e-04, -6.53104798e-04, -4.55490634e-04,\n",
       "       -8.73026846e-04, -1.11140453e-05, -6.25808680e-05,  4.51345433e-04,\n",
       "       -6.39769933e-05,  2.54662824e-04,  9.38705518e-04,  7.27004197e-04,\n",
       "        8.44968832e-04,  5.31265163e-04, -4.48060542e-04,  3.25839937e-04,\n",
       "       -4.69851075e-04, -8.00624330e-05, -5.93469245e-04,  3.21270345e-04,\n",
       "       -6.70534442e-04,  1.92446212e-04,  5.30107471e-04, -9.32547206e-04,\n",
       "        6.97827549e-04, -8.87177535e-04, -4.68109560e-04,  3.28907219e-04,\n",
       "       -3.18687409e-04, -1.73884808e-04, -3.20905936e-04,  3.88944260e-04,\n",
       "       -7.04762118e-04, -1.58326307e-04,  4.30793501e-04,  1.99687405e-04,\n",
       "       -5.03963383e-04,  7.79088063e-04,  5.45681978e-04,  3.40783881e-04,\n",
       "        5.55232284e-04,  1.29676031e-04,  3.55234311e-04, -1.61372387e-04,\n",
       "        5.31847298e-04,  1.84442775e-04,  1.20633078e-04, -9.89191467e-04,\n",
       "       -1.65743404e-04,  1.59388714e-04,  8.00843700e-04,  8.58181811e-05,\n",
       "        5.39935718e-04,  9.31242830e-04, -4.85109980e-04,  6.09045719e-06,\n",
       "       -4.69061226e-04, -6.86632528e-04,  9.96401883e-04,  7.85991258e-04,\n",
       "        2.68426171e-04,  2.28550125e-04, -4.05258819e-04, -7.77496782e-04,\n",
       "        2.17789013e-04,  4.43196768e-04,  1.50582593e-04,  2.68459407e-04,\n",
       "        1.28968066e-04, -1.49080020e-04, -2.92783021e-04,  1.78035611e-04,\n",
       "       -9.41688195e-04,  6.08045608e-04,  3.28232767e-04,  1.29123160e-04,\n",
       "       -1.30243396e-04, -3.93469527e-04, -4.01312602e-04,  1.92524210e-04,\n",
       "       -1.50609791e-04,  4.91313403e-04, -5.19507856e-04,  9.79891265e-05,\n",
       "        4.72360989e-04,  8.13977618e-04, -4.91635408e-04, -5.55275823e-04,\n",
       "        4.25664126e-04,  1.48534833e-04, -4.99861839e-04,  8.11302816e-05,\n",
       "       -2.61180394e-04, -2.49980312e-05,  3.69826128e-04,  1.21714736e-04,\n",
       "        9.27532790e-04, -1.92028747e-04,  1.18379838e-04,  1.02727026e-04,\n",
       "       -1.82618984e-04, -3.89489345e-04, -8.87477596e-04, -5.59364853e-04,\n",
       "       -2.30580088e-04,  7.57925212e-04,  5.10870777e-08,  8.22881237e-04,\n",
       "       -3.72001494e-04, -9.10649309e-04,  5.56674844e-04, -2.21803901e-04,\n",
       "        7.20687676e-05, -2.04651155e-06, -5.20740054e-04, -2.16024811e-04,\n",
       "       -6.10542120e-05,  8.82421096e-04, -6.35868870e-04,  5.80187712e-04,\n",
       "       -8.59890832e-04, -4.00535442e-04,  4.86551784e-04,  9.58116085e-04,\n",
       "       -8.82705208e-04, -9.49913519e-04, -9.32649011e-04, -1.82643809e-04,\n",
       "       -7.78977294e-04, -5.61823894e-04, -3.75437958e-04, -8.77833867e-04,\n",
       "        4.18640848e-04,  7.09765882e-04,  1.92744439e-04, -3.28871160e-04,\n",
       "        4.11740621e-04,  8.91826523e-04,  5.57170773e-04, -7.54042412e-04,\n",
       "        3.24630790e-04, -8.86625261e-04, -6.56184042e-04, -6.81237318e-04,\n",
       "        1.62295444e-04,  2.17728393e-05,  2.49717879e-04,  4.61685850e-04,\n",
       "        3.21078842e-04,  5.72850171e-04, -5.50908699e-05,  2.94091820e-04,\n",
       "       -4.29388514e-04,  5.08719706e-04,  9.73390357e-04, -5.32843114e-04,\n",
       "        7.38677918e-04, -2.28982302e-04,  5.84695605e-04, -1.49660220e-04,\n",
       "       -1.34141970e-04, -5.34289808e-04,  3.36445140e-04,  9.32746159e-04,\n",
       "       -7.37163355e-04, -3.08107235e-04, -3.80790967e-04,  4.69654915e-04,\n",
       "       -1.75859866e-04, -1.44708720e-05,  8.57302162e-04,  1.70547777e-04,\n",
       "       -2.90924596e-04, -6.58114324e-04, -9.48028639e-04,  6.38771162e-04,\n",
       "        1.44899910e-04, -7.68026293e-05,  7.89632759e-05, -5.14517706e-05,\n",
       "       -1.94739958e-04, -7.33126129e-04, -9.47611057e-04,  1.43089448e-04,\n",
       "        4.22125246e-04,  3.05313733e-04, -6.40842773e-04,  3.83114821e-04,\n",
       "       -8.88827315e-04,  6.36793557e-04,  3.50715651e-04, -1.09488217e-04,\n",
       "        4.67831502e-04, -2.41307585e-04,  7.27698207e-04, -1.17287469e-04,\n",
       "        4.66829079e-04, -5.25165000e-04,  5.85723756e-05, -6.63417624e-04,\n",
       "       -8.20788264e-04,  6.20922074e-04,  1.21489298e-04, -3.71109054e-04,\n",
       "       -8.97276215e-04,  4.85458935e-04, -6.21066603e-04, -4.47065948e-04,\n",
       "       -2.45246716e-04, -1.94957145e-04,  9.22053645e-04, -7.66679819e-04,\n",
       "        3.01224354e-04,  5.75143204e-04, -8.91014817e-04, -4.51040018e-04,\n",
       "        6.22652762e-04, -4.80424525e-04, -5.81088767e-04,  5.58313448e-04,\n",
       "       -4.92768129e-04, -6.44036685e-04,  7.70777115e-04, -4.73198510e-04,\n",
       "       -1.72426357e-04,  5.22528309e-04, -5.10918908e-04,  9.37827164e-04,\n",
       "       -5.55966471e-05, -7.90599850e-04, -8.29357305e-04, -3.53207928e-04,\n",
       "        6.24081993e-04,  7.10861350e-04, -8.32612684e-04,  6.30459865e-04,\n",
       "       -9.13719414e-04,  6.66664040e-04, -8.52710975e-04, -9.21544197e-05,\n",
       "       -4.42478660e-04, -9.30297945e-04,  9.64626495e-04, -5.45694900e-04,\n",
       "        4.40601609e-04,  8.21069581e-04,  5.71138808e-04,  6.85812905e-04,\n",
       "       -5.21122129e-04, -6.39759586e-04, -2.29368990e-04, -8.60321743e-04,\n",
       "        3.94304865e-04,  4.82554751e-04,  3.31501760e-05,  7.67567777e-04,\n",
       "        4.42452583e-04, -5.13408741e-04, -6.86341664e-05,  4.26317674e-05,\n",
       "       -6.12642791e-04,  5.49040909e-04,  8.90910800e-04,  5.86413313e-04,\n",
       "        1.89756101e-04,  1.22140875e-04,  5.80846332e-04,  3.52921023e-04,\n",
       "        1.80602467e-04,  4.49634827e-04,  9.08432994e-04, -6.19564162e-05,\n",
       "       -5.85122798e-05,  9.52502945e-04,  6.60191756e-04,  8.59128311e-04,\n",
       "       -4.87908110e-05, -5.80205466e-04,  3.67118628e-04,  2.89725605e-04])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 954,
     "status": "ok",
     "timestamp": 1536045409690,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "BQdnXhFicGeG",
    "outputId": "9cdbd994-6a83-493f-f4ff-330d41f0769b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['—', 'tu', 'sais', 'ce', 'que', 'c’', 'est', '?']"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xghih9x2cc4u"
   },
   "source": [
    "## Create the Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 9059,
     "status": "ok",
     "timestamp": 1536045518466,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "9ZW3EQc4cimx",
    "outputId": "a9b1987d-66d4-4ea5-abaf-e2e7d0c48d2b"
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout, Embedding, Flatten, Bidirectional, Input, LSTM\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_accuracy, mean_squared_error, mean_absolute_error, logcosh\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "def bidirectional_lstm_model(seq_length, vector_dim):\n",
    "    print('Building LSTM model...')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vector_dim)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(vector_dim))\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
    "    model.compile(loss='logcosh', optimizer=optimizer, metrics=['acc'])\n",
    "    print('LSTM model built.')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2536,
     "status": "ok",
     "timestamp": 1536045535745,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "rgn8_WnFcmqk",
    "outputId": "24383c5a-c107-47d8-ac63-16ba459b79f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building LSTM model...\n",
      "LSTM model built.\n"
     ]
    }
   ],
   "source": [
    "rnn_size = 512 # size of RNN\n",
    "vector_dim = 500\n",
    "learning_rate = 0.0001 #learning rate\n",
    "\n",
    "model_sequence = bidirectional_lstm_model(nb_sequenced_sentences, vector_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 666
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 118221,
     "status": "ok",
     "timestamp": 1536045709810,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "Nnuo2HYpcsd7",
    "outputId": "c466dd02-9db9-4176-ed5c-4f12cd0ec0dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2197 samples, validate on 245 samples\n",
      "Epoch 1/40\n",
      "2197/2197 [==============================] - 11s 5ms/step - loss: 1.7604e-07 - acc: 0.0036 - val_loss: 1.5787e-07 - val_acc: 0.0000e+00\n",
      "Epoch 2/40\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 1.7057e-07 - acc: 0.0018 - val_loss: 1.5828e-07 - val_acc: 0.0000e+00\n",
      "Epoch 3/40\n",
      "2197/2197 [==============================] - 8s 4ms/step - loss: 1.7015e-07 - acc: 0.0023 - val_loss: 1.5809e-07 - val_acc: 0.0000e+00\n",
      "Epoch 4/40\n",
      "2197/2197 [==============================] - 7s 3ms/step - loss: 1.7004e-07 - acc: 0.0027 - val_loss: 1.5815e-07 - val_acc: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30 # minibatch size\n",
    "\n",
    "callbacks=[EarlyStopping(patience=3, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath=save_dir + \"/\" + 'my_model_sequence_lstm.{epoch:02d}.hdf5',\\\n",
    "                           monitor='val_loss', verbose=1, mode='auto', period=5)]\n",
    "\n",
    "history = model_sequence.fit(X_train, y_train,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=40,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_split=0.1)\n",
    "\n",
    "#save the model\n",
    "model_sequence.save(save_dir + \"/\" + 'my_model_sequence_lstm.final2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nHqZ_dOTcyOD"
   },
   "source": [
    "## Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import os\n",
    "import scipy\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = '../out' # directory to store models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fr_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz#egg=fr_core_news_sm==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
      "    /usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import spacy, and french model\n",
    "import spacy\n",
    "! python -m spacy download fr\n",
    "nlp = spacy.load('fr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.14.5)\n",
      "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.11.0)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.6.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (0.19.1)\n",
      "Requirement already satisfied: bz2file in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (0.98)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.18.4)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.9.0)\n",
      "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2018.8.24)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.6)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.3)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.12.0)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.1.13)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim) (2.5.3)\n",
      "Requirement already satisfied: docutils>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.0->boto3->smart-open>=1.2.1->gensim) (0.14)\n"
     ]
    }
   ],
   "source": [
    "! pip install gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load **doc2vec** model we created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading doc2Vec model...\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "#import gensim library\n",
    "import gensim\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "#load the doc2vec model\n",
    "print(\"loading doc2Vec model...\")\n",
    "d2v_model = gensim.models.doc2vec.Doc2Vec.load('../out/doc2vec.w2v')\n",
    "\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **words_vocab** model created in the first notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary...\n",
      "vocabulary loaded !\n"
     ]
    }
   ],
   "source": [
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "\n",
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "\n",
    "vocab_size = len(words)\n",
    "print(\"vocabulary loaded !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the **word prediction model** created in the first notebook and **sentence selection model** created above in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The perpose of creating two model is, **word prediction model** will generate several sentence prediction and **sentence selection model** will choose the best sentece among them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading word prediction model...\n",
      "model loaded!\n",
      "loading sentence selection model...\n",
      "model loaded!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# load the keras models\n",
    "print(\"loading word prediction model...\")\n",
    "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')\n",
    "print(\"model loaded!\")\n",
    "print(\"loading sentence selection model...\")\n",
    "model_sequence = load_model(save_dir + \"/\" + 'my_model_sequence_lstm.final2.hdf5')\n",
    "print(\"model loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to generate Candidates Sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function **sample()**, will draw randomly a word from our vocabulary.but probability for a word to be drawn will depends directly on its probability to be the next word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\"temperature\"** to smooth or sharpen its value.<br>\n",
    "-  if temperature = 1.0, the probability for a word to be drawn is equal to the probability for the word to be the next one in the sequence (output of the owrd prediction model),\n",
    "2. if temperature is big (much bigger than 1), the range of probabilities is shorten: the probabilities for all words to be the next one is closer to 1. More variety of words will be picked-up from the vocabulary.\n",
    "3. if temperatune is small (close to 0), small probabilities will be avoided (they will be set closed to 0). Less words will be picked-up from the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 10.4 GB  | Proc size: 3.6 GB\n",
      "GPU RAM Free: 548MB | Used: 10891MB | Util  95% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**create_seed** function read the last few words from the given sentence(**seed_sentences**) as a input text to generate output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_seed(seed_sentences,nb_words_in_seq=20, verbose=False):\n",
    "    #initiate sentences\n",
    "    generated = ''\n",
    "    sentence = []\n",
    "    \n",
    "    #fill the sentence with a default word\n",
    "    for i in range (nb_words_in_seq):\n",
    "        sentence.append(\"le\")\n",
    "\n",
    "    seed = seed_sentences.split()\n",
    "    \n",
    "    if verbose == True : print(\"seed: \",seed)\n",
    "\n",
    "    for i in range(len(sentence)):\n",
    "        sentence[nb_words_in_seq-i-1]=seed[len(seed)-i-1]\n",
    "        print(i, sentence)\n",
    "\n",
    "    generated += ' '.join(sentence)\n",
    "    \n",
    "    if verbose == True : print('Generating text with the following seed: \"' + ' '.join(sentence) + '\"')\n",
    "\n",
    "    return [generated, sentence]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate_phrase()** is used to create the next phrase of a given sentence.\n",
    "\n",
    "It requires as inputs:\n",
    "\n",
    "- the previous sentence,\n",
    "- the maximum number of words in the phrase,\n",
    "- the temperature of the sample function.<br> If a punctuation word is reached before the maximum number of the words, the function ends."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phrase(sentence, max_words = 50, nb_words_in_seq=20, temperature=1, verbose = False):\n",
    "    generated = \"\"\n",
    "    words_number = max_words - 1\n",
    "    ponctuation = [\".\",\"?\",\"!\",\":\",\"…\"]\n",
    "    seq_length = nb_words_in_seq\n",
    "    #sentence = []\n",
    "    is_punct = False\n",
    "    \n",
    "    #generate the text\n",
    "    for i in range(words_number):\n",
    "        #create the vector\n",
    "        x = np.zeros((1, seq_length, vocab_size))\n",
    "        for t, word in enumerate(sentence):\n",
    "            #print(t, word, vocab[word])\n",
    "            if word not in vocab:\n",
    "                word = \"nolan\"\n",
    "            x[0, nb_words_in_seq-len(sentence)+t, vocab[word]] = 1.\n",
    "        #print(x.shape)\n",
    "\n",
    "        #calculate next word\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature)\n",
    "        next_word = vocabulary_inv[next_index]\n",
    "        \n",
    "        if verbose == True:\n",
    "            predv = np.array(preds)\n",
    "            #arr = np.array([1, 3, 2, 4, 5])\n",
    "            wi = predv.argsort()[-3:][::-1]\n",
    "            print(\"potential next words: \", vocabulary_inv[wi[0]], vocabulary_inv[wi[1]], vocabulary_inv[wi[2]])\n",
    "\n",
    "        #add the next word to the text\n",
    "        if is_punct == False:\n",
    "            if next_word in ponctuation:\n",
    "                is_punct = True\n",
    "            generated += \" \" + next_word\n",
    "            # shift the sentence by one, and and the next word at its end\n",
    "            sentence = sentence[1:] + [next_word]\n",
    "\n",
    "    return(generated, sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**define_phrases_candidates()** provides a list of probable phrases, for a given previous sentence and a specific temperature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def define_phrases_candidates(sentence, max_words = 50,\\\n",
    "                              nb_words_in_seq=20, \\\n",
    "                              temperature=1, \\\n",
    "                              nb_candidates_sents=10, \\\n",
    "                              verbose = False):\n",
    "    phrase_candidate = []\n",
    "    generated_sentence = \"\"\n",
    "    for i in range(nb_candidates_sents):\n",
    "        generated_sentence, new_sentence = generate_phrase(sentence, \\\n",
    "                                                           max_words = max_words, \\\n",
    "                                                           nb_words_in_seq = nb_words_in_seq, \\\n",
    "                                                           temperature=temperature, \\\n",
    "                                                           verbose = False)\n",
    "        phrase_candidate.append([generated_sentence, new_sentence])\n",
    "    \n",
    "    if verbose == True :\n",
    "        for phrase in phrase_candidate:\n",
    "            print(\"   \" , phrase[0])\n",
    "    return phrase_candidate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to select the best sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***infer_vector -- *** Subsequent calls to this function may infer different representations for the same document. For a more stable representation, increase the number of steps to assert a stricket convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**generate_training_vector()** generate a vector for each sentence in the sentence list.<br>\n",
    "As **infer_vector** define a new representation of a sentence,so the function is used to predict the next vectorized-sentence for a given sequence of vectorized-sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_vector(sentences_list, verbose = False):\n",
    "    if verbose == True : print(\"generate vectors for each sentence...\")\n",
    "    seq = []\n",
    "    V = []\n",
    "\n",
    "    for s in sentences_list:\n",
    "        #infer the vector of the sentence, from the doc2vec model\n",
    "        print(s)\n",
    "        v = d2v_model.infer_vector(create_sentences(nlp(s))[0], alpha=0.001, min_alpha=0.001, steps=10000)\n",
    "    #create the vector array for the model\n",
    "        #print(len(v))\n",
    "        V.append(v)\n",
    "    V_val=np.array(V)\n",
    "    #expand dimension to fit the entry of the model : that's the training vector\n",
    "    V_val = np.expand_dims(V_val, axis=0)\n",
    "    if verbose == True : print(\"Vectors generated!\")\n",
    "    return V_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **select_next_phrase()** function allows us to pick-up the best candidates for the next phrase.\n",
    "\n",
    "First, it calculates the vector for each candidates.\n",
    "\n",
    "Then, based on the vector generated by the function **generate_training_vector()**, it performs a cosine similarity with them and pick the one with the biggest similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_next_phrase(model, V_val, candidate_list, verbose=False):\n",
    "    sims_list = []\n",
    "    \n",
    "    #calculate prediction\n",
    "    preds = model.predict(V_val, verbose=0)[0]\n",
    "    \n",
    "    #calculate vector for each candidate\n",
    "    for candidate in candidate_list:\n",
    "        #calculate vector\n",
    "        #print(\"calculate vector for : \", candidate[1])\n",
    "        V = np.array(d2v_model.infer_vector(candidate[1]))\n",
    "        #calculate csonie similarity\n",
    "        sim = scipy.spatial.distance.cosine(V,preds)\n",
    "        #populate list of similarities\n",
    "        sims_list.append(sim)\n",
    "    \n",
    "    #select index of the biggest similarity\n",
    "    m = max(sims_list)\n",
    "    index_max = sims_list.index(m)\n",
    "    \n",
    "    if verbose == True :\n",
    "        print(\"selected phrase :\")\n",
    "        print(\"     \", candidate_list[index_max][0])\n",
    "    return candidate_list[index_max]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation - workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraphe(phrase_seed, sentences_seed, \\\n",
    "                        max_words = 50, \\\n",
    "                        nb_words_in_seq=20, \\\n",
    "                        temperature=1, \\\n",
    "                        nb_phrases=30, \\\n",
    "                        nb_candidates_sents=10, \\\n",
    "                        verbose=True):\n",
    "    \n",
    "    sentences_list = sentences_seed\n",
    "    sentence = phrase_seed   \n",
    "    text = []\n",
    "    \n",
    "    for p in range(nb_phrases):\n",
    "        if verbose == True : print(\"\")\n",
    "        if verbose == True : print(\"#############\")\n",
    "        print(\"phrase \",p+1, \"/\", nb_phrases)\n",
    "        if verbose == True : print(\"#############\")       \n",
    "        if verbose == True:\n",
    "            print('Sentence to generate phrase : ')\n",
    "            print(\"     \", sentence)\n",
    "            print(\"\")\n",
    "            print('List of sentences to constrain next phrase : ')\n",
    "            print(\"     \", sentences_list)\n",
    "            print(\"\")\n",
    "    \n",
    "        #generate seed training vector\n",
    "        V_val = generate_training_vector(sentences_list, verbose = verbose)\n",
    "\n",
    "        #generate phrase candidate\n",
    "        if verbose == True : print(\"generate phrases candidates...\")\n",
    "        phrases_candidates = define_phrases_candidates(sentence, \\\n",
    "                                                       max_words = max_words, \\\n",
    "                                                       nb_words_in_seq = nb_words_in_seq, \\\n",
    "                                                       temperature=temperature, \\\n",
    "                                                       nb_candidates_sents=nb_candidates_sents, \\\n",
    "                                                       verbose = verbose)\n",
    "        \n",
    "        if verbose == True : print(\"select next phrase...\")\n",
    "        next_phrase = select_next_phrase(model_sequence, \\\n",
    "                                         V_val,\n",
    "                                         phrases_candidates, \\\n",
    "                                         verbose=verbose)\n",
    "        \n",
    "        print(\"Next phrase: \",next_phrase[0])\n",
    "        if verbose == True :\n",
    "            print(\"\")\n",
    "            print(\"Shift phrases in sentences list...\")\n",
    "        for i in range(len(sentences_list)-1):\n",
    "            sentences_list[i]=sentences_list[i+1]\n",
    "\n",
    "        sentences_list[len(sentences_list)-1] = next_phrase[0]\n",
    "        \n",
    "        if verbose == True:\n",
    "            print(\"done.\")\n",
    "            print(\"new list of sentences :\")\n",
    "            print(\"     \", sentences_list)     \n",
    "        sentence = next_phrase[1]\n",
    "        \n",
    "        text.append(next_phrase[0])\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define some training sentence and combine them in a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = \"nolan s' approche du bord du chemin et regarde en contrebas .\"\n",
    "s2 = \"il se tourne vers mara :\"\n",
    "s3 = \"- que dis tu ?\"\n",
    "s4 = \"- rien du tout , lui répond la jeune femme en détournant le regard .\"\n",
    "s5 = \"- je t' ai entendu dire quelque chose , pourtant .\"\n",
    "s6 = \"- je pensais à voix haute , explique mara  .\"\n",
    "s7 = \"l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\"\n",
    "s8 = \"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\"\n",
    "s9 = \"- je crois avoir vu une ombre , déclare finalement la jeune femme .\"\n",
    "s10 = \"- à quel endroit ?\"\n",
    "s11 = \"s' écrie le jeune homme .\"\n",
    "s12 = \"nolan semble bouleversé et il est devenu blanc de peur .\"\n",
    "s13 = \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\"\n",
    "s14 = \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\"\n",
    "s15 = \"il y a probablement une erreur .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"nolan s' approche du bord du chemin et regarde en contrebas .\", 'il se tourne vers mara :', '- que dis tu ?', '- rien du tout , lui répond la jeune femme en détournant le regard .', \"- je t' ai entendu dire quelque chose , pourtant .\", '- je pensais à voix haute , explique mara  .', \"l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\", \"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\", '- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .']\n"
     ]
    }
   ],
   "source": [
    "sentences_list = [s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15]\n",
    "print(sentences_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed:  ['nolan', \"s'\", 'approche', 'du', 'bord', 'du', 'chemin', 'et', 'regarde', 'en', 'contrebas', '.', 'il', 'se', 'tourne', 'vers', 'mara', ':', '-', 'que', 'dis', 'tu', '?', '-', 'rien', 'du', 'tout', ',', 'lui', 'répond', 'la', 'jeune', 'femme', 'en', 'détournant', 'le', 'regard', '.', '-', 'je', \"t'\", 'ai', 'entendu', 'dire', 'quelque', 'chose', ',', 'pourtant', '.', '-', 'je', 'pensais', 'à', 'voix', 'haute', ',', 'explique', 'mara', '.', \"l'\", 'apprentie', 'hésite', ',', 'elle', \"n'\", 'est', 'pas', 'certaine', 'que', 'nolan', 'comprenne', '.', 'depuis', 'quelques', 'jours', ',', 'nolan', 'est', 'à', 'fleur', 'de', 'peau', 'et', \"s'inquiète\", 'pour', 'un', 'rien', '.', '-', 'je', 'crois', 'avoir', 'vu', 'une', 'ombre', ',', 'déclare', 'finalement', 'la', 'jeune', 'femme', '.', '-', 'à', 'quel', 'endroit', '?', \"s'\", 'écrie', 'le', 'jeune', 'homme', '.', 'nolan', 'semble', 'bouleversé', 'et', 'il', 'est', 'devenu', 'blanc', 'de', 'peur', '.', 'les', 'souvenirs', 'des', 'kaurocs', 'sont', 'suffisament', 'frais', 'dans', 'sa', 'mémoire', 'pour', \"qu'\", 'une', 'étrange', 'angoisse', 'lui', 'noue', 'la', 'poitrine', '.', '-', 'ne', 'sois', 'pas', 'inquiet', ',', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "0 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', '.']\n",
      "1 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'erreur', '.']\n",
      "2 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'une', 'erreur', '.']\n",
      "3 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'probablement', 'une', 'erreur', '.']\n",
      "4 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "5 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "6 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "7 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "8 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "9 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "10 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "11 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'le', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "12 ['le', 'le', 'le', 'le', 'le', 'le', 'le', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "13 ['le', 'le', 'le', 'le', 'le', 'le', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "14 ['le', 'le', 'le', 'le', 'le', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "15 ['le', 'le', 'le', 'le', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "16 ['le', 'le', 'le', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "17 ['le', 'le', 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "18 ['le', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "19 [',', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "Generating text with the following seed: \", s' exclame mara , confuse de la réaction de son ami . il y a probablement une erreur .\"\n",
      ", s' exclame mara , confuse de la réaction de son ami . il y a probablement une erreur .\n",
      "[',', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n"
     ]
    }
   ],
   "source": [
    "phrase_seed, sentences_seed = create_seed(s1 + \" \" + s2 + \" \" +\\\n",
    "                                          s3 + \" \" + s4+ \" \" + s5 + \" \" +\\\n",
    "                                          s6 + \" \" + s7 + \" \" + s8 + \" \" +\\\n",
    "                                          s9+ \" \" + s10 + \" \" + s11 + \" \" +\\\n",
    "                                          s12 + \" \" + s13 + \" \" + s14+ \" \" + s15,20,True)\n",
    "print(phrase_seed)\n",
    "print(sentences_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now generate the actual text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "#############\n",
      "phrase  1 / 5\n",
      "#############\n",
      "Sentence to generate phrase : \n",
      "      [',', \"s'\", 'exclame', 'mara', ',', 'confuse', 'de', 'la', 'réaction', 'de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.']\n",
      "\n",
      "List of sentences to constrain next phrase : \n",
      "      [\"l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\", \"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\", '- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .']\n",
      "\n",
      "generate vectors for each sentence...\n",
      "l' apprentie hésite , elle n' est pas certaine que nolan comprenne .\n",
      "depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\n",
      "- je crois avoir vu une ombre , déclare finalement la jeune femme .\n",
      "- à quel endroit ?\n",
      "s' écrie le jeune homme .\n",
      "nolan semble bouleversé et il est devenu blanc de peur .\n",
      "les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\n",
      "- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\n",
      "il y a probablement une erreur .\n",
      " le ne pas la est pas et .\n",
      " .\n",
      " — il est est est de pas une œil .\n",
      " la jeune s’ se jeune .\n",
      " , la tête de .\n",
      " , , la plus est , , , l’ est pas .\n",
      "Vectors generated!\n",
      "generate phrases candidates...\n",
      "     de la en ne pas la la citadelle .\n",
      "     les plus en ne pas , .\n",
      "     la , , , pour en les pas les s’ yeux .\n",
      "     le est , , .\n",
      "     de s’ de les la jeune .\n",
      "     .\n",
      "     , , , en est on fait la est est la jeune .\n",
      "select next phrase...\n",
      "selected phrase :\n",
      "       de la en ne pas la la citadelle .\n",
      "Next phrase:   de la en ne pas la la citadelle .\n",
      "\n",
      "Shift phrases in sentences list...\n",
      "done.\n",
      "new list of sentences :\n",
      "      [\"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\", '- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .']\n",
      "\n",
      "#############\n",
      "phrase  2 / 5\n",
      "#############\n",
      "Sentence to generate phrase : \n",
      "      ['de', 'son', 'ami', '.', 'il', 'y', 'a', 'probablement', 'une', 'erreur', '.', 'de', 'la', 'en', 'ne', 'pas', 'la', 'la', 'citadelle', '.']\n",
      "\n",
      "List of sentences to constrain next phrase : \n",
      "      [\"depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\", '- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .']\n",
      "\n",
      "generate vectors for each sentence...\n",
      "depuis quelques jours , nolan est à fleur de peau et s'inquiète pour un rien .\n",
      "- je crois avoir vu une ombre , déclare finalement la jeune femme .\n",
      "- à quel endroit ?\n",
      "s' écrie le jeune homme .\n",
      "nolan semble bouleversé et il est devenu blanc de peur .\n",
      "les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\n",
      "- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\n",
      "il y a probablement une erreur .\n",
      " le ne pas la est pas et .\n",
      " .\n",
      " — il est est est de pas une œil .\n",
      " la jeune s’ se jeune .\n",
      " , la tête de .\n",
      " , , la plus est , , , l’ est pas .\n",
      " de la en ne pas la la citadelle .\n",
      "Vectors generated!\n",
      "generate phrases candidates...\n",
      "     de la tête .\n",
      "     .\n",
      "     — je vous vous vous pas ne pas nous pas le pas , la direction .\n",
      "     l’ est de la tête les jeune .\n",
      "     — , , pas , pas , en citadelle , , .\n",
      "     , le l’ en yeux , l’ plus une on main et et la en yeux .\n",
      "     , , , la tête , , de leurs la jeune .\n",
      "select next phrase...\n",
      "selected phrase :\n",
      "       , le l’ en yeux , l’ plus une on main et et la en yeux .\n",
      "Next phrase:   , le l’ en yeux , l’ plus une on main et et la en yeux .\n",
      "\n",
      "Shift phrases in sentences list...\n",
      "done.\n",
      "new list of sentences :\n",
      "      ['- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .', ' , le l’ en yeux , l’ plus une on main et et la en yeux .']\n",
      "\n",
      "#############\n",
      "phrase  3 / 5\n",
      "#############\n",
      "Sentence to generate phrase : \n",
      "      ['la', 'citadelle', '.', ',', 'le', 'l’', 'en', 'yeux', ',', 'l’', 'plus', 'une', 'on', 'main', 'et', 'et', 'la', 'en', 'yeux', '.']\n",
      "\n",
      "List of sentences to constrain next phrase : \n",
      "      ['- je crois avoir vu une ombre , déclare finalement la jeune femme .', '- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .', ' , le l’ en yeux , l’ plus une on main et et la en yeux .']\n",
      "\n",
      "generate vectors for each sentence...\n",
      "- je crois avoir vu une ombre , déclare finalement la jeune femme .\n",
      "- à quel endroit ?\n",
      "s' écrie le jeune homme .\n",
      "nolan semble bouleversé et il est devenu blanc de peur .\n",
      "les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\n",
      "- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\n",
      "il y a probablement une erreur .\n",
      " le ne pas la est pas et .\n",
      " .\n",
      " — il est est est de pas une œil .\n",
      " la jeune s’ se jeune .\n",
      " , la tête de .\n",
      " , , la plus est , , , l’ est pas .\n",
      " de la en ne pas la la citadelle .\n",
      " , le l’ en yeux , l’ plus une on main et et la en yeux .\n",
      "Vectors generated!\n",
      "generate phrases candidates...\n",
      "     la tête .\n",
      "     , , le est se à la tête .\n",
      "     , un tête la est ne pas pas et à la ne pas se penche de la .\n",
      "     de la tête .\n",
      "     les la tête , la .\n",
      "     — , , , , , , , vous , , s’ , .\n",
      "     de la tête .\n",
      "select next phrase...\n",
      "selected phrase :\n",
      "       de la tête .\n",
      "Next phrase:   de la tête .\n",
      "\n",
      "Shift phrases in sentences list...\n",
      "done.\n",
      "new list of sentences :\n",
      "      ['- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .', ' , le l’ en yeux , l’ plus une on main et et la en yeux .', ' de la tête .']\n",
      "\n",
      "#############\n",
      "phrase  4 / 5\n",
      "#############\n",
      "Sentence to generate phrase : \n",
      "      ['le', 'l’', 'en', 'yeux', ',', 'l’', 'plus', 'une', 'on', 'main', 'et', 'et', 'la', 'en', 'yeux', '.', 'de', 'la', 'tête', '.']\n",
      "\n",
      "List of sentences to constrain next phrase : \n",
      "      ['- à quel endroit ?', \"s' écrie le jeune homme .\", 'nolan semble bouleversé et il est devenu blanc de peur .', \"les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\", \"- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\", 'il y a probablement une erreur .', ' le ne pas la est pas et .', ' .', ' — il est est est de pas une œil .', ' la jeune s’ se jeune .', ' , la tête de .', ' , , la plus est , , , l’ est pas .', ' de la en ne pas la la citadelle .', ' , le l’ en yeux , l’ plus une on main et et la en yeux .', ' de la tête .']\n",
      "\n",
      "generate vectors for each sentence...\n",
      "- à quel endroit ?\n",
      "s' écrie le jeune homme .\n",
      "nolan semble bouleversé et il est devenu blanc de peur .\n",
      "les souvenirs des kaurocs sont suffisament frais dans sa mémoire pour qu' une étrange angoisse lui noue la poitrine .\n",
      "- ne sois pas inquiet , s' exclame mara , confuse de la réaction de son ami .\n",
      "il y a probablement une erreur .\n",
      " le ne pas la est pas et .\n",
      " .\n",
      " — il est est est de pas une œil .\n",
      " la jeune s’ se jeune .\n",
      " , la tête de .\n",
      " , , la plus est , , , l’ est pas .\n"
     ]
    }
   ],
   "source": [
    "text = generate_paragraphe(sentences_seed, sentences_list, \\\n",
    "                           max_words = 80, \\\n",
    "                           nb_words_in_seq = 30,\\\n",
    "                           temperature=0.201, \\\n",
    "                           nb_phrases=5, \\\n",
    "                           nb_candidates_sents=7, \\\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printm()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Text Generation part 2.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
