{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r5zbkgNt20FO"
   },
   "outputs": [],
   "source": [
    "#from google.colab import files\n",
    "#uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wskrXMeV5MyI"
   },
   "outputs": [],
   "source": [
    "#file_names =[]\n",
    "#for file in uploaded.keys():\n",
    "#  file_names.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 845,
     "status": "ok",
     "timestamp": 1535998977040,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "XrMiBXU_7II3",
    "outputId": "67b062da-d49f-418d-c053-4950a7fa676e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['408.txt',\n",
       " '104.txt',\n",
       " '301.txt',\n",
       " '405.txt',\n",
       " '407.txt',\n",
       " '310.txt',\n",
       " '211.txt',\n",
       " '411.txt',\n",
       " '303.txt',\n",
       " '203.txt',\n",
       " '304.txt',\n",
       " '107.txt',\n",
       " '309.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "path = \"../data/\"\n",
    "file_list = os.listdir( path )\n",
    "\n",
    "remove_files = ['input.txt','LICENSE']\n",
    "for r_files in remove_files:\n",
    "    file_list.remove(r_files)\n",
    "\n",
    "file_list = file_list[:13]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7342,
     "status": "ok",
     "timestamp": 1535998987705,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "MtifrvemQLCV",
    "outputId": "6b9a87c4-1ac7-4a09-e562-95558a37e376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gputil\n",
      "  Downloading https://files.pythonhosted.org/packages/45/99/837428d26b47ebd6b66d6e1b180e98ec4a557767a93a81a02ea9d6242611/GPUtil-1.3.0.tar.gz\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from gputil) (1.14.5)\n",
      "Building wheels for collected packages: gputil\n",
      "  Running setup.py bdist_wheel for gputil ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/17/0f/04/b79c006972335e35472c0b835ed52bfc0815258d409f560108\n",
      "Successfully built gputil\n",
      "Installing collected packages: gputil\n",
      "Successfully installed gputil-1.3.0\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.7)\n",
      "Collecting humanize\n",
      "  Downloading https://files.pythonhosted.org/packages/8c/e0/e512e4ac6d091fc990bbe13f9e0378f34cf6eecd1c6c268c9e598dcf5bb9/humanize-0.5.1.tar.gz\n",
      "Building wheels for collected packages: humanize\n",
      "  Running setup.py bdist_wheel for humanize ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/69/86/6c/f8b8593bc273ec4b0c653d3827f7482bb2001a2781a73b7f44\n",
      "Successfully built humanize\n",
      "Installing collected packages: humanize\n",
      "Successfully installed humanize-0.5.1\n",
      "Gen RAM Free: 12.4 GB  | Proc size: 142.1 MB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "!pip install gputil\n",
    "!pip install psutil\n",
    "!pip install humanize\n",
    "import psutil\n",
    "import humanize\n",
    "import os\n",
    "import GPUtil as GPU\n",
    "GPUs = GPU.getGPUs()\n",
    "# XXX: only one GPU on Colab and isn’t guaranteed\n",
    "gpu = GPUs[0]\n",
    "def printm():\n",
    "    process = psutil.Process(os.getpid())\n",
    "    print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
    "    print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
    "printm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "810KfZCw7XQy"
   },
   "source": [
    "## Import Dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18358,
     "status": "ok",
     "timestamp": 1535999009356,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "HP_eaXzs7fg-",
    "outputId": "97e9c913-2d86-4f75-bcd1-fbbb00ca254a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (2.0.12)\n",
      "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.14.5)\n",
      "Requirement already satisfied: murmurhash<0.29,>=0.28 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.28.0)\n",
      "Requirement already satisfied: cymem<1.32,>=1.30 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.31.2)\n",
      "Requirement already satisfied: preshed<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: thinc<6.11.0,>=6.10.3 in /usr/local/lib/python3.6/dist-packages (from spacy) (6.10.3)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.9.6)\n",
      "Requirement already satisfied: ujson>=1.35 in /usr/local/lib/python3.6/dist-packages (from spacy) (1.35)\n",
      "Requirement already satisfied: dill<0.3,>=0.2 in /usr/local/lib/python3.6/dist-packages (from spacy) (0.2.8.2)\n",
      "Requirement already satisfied: regex==2017.4.5 in /usr/local/lib/python3.6/dist-packages (from spacy) (2017.4.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy) (2.18.4)\n",
      "Requirement already satisfied: msgpack<1.0.0,>=0.5.6 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.5.6)\n",
      "Requirement already satisfied: msgpack-numpy<1.0.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.4.3.1)\n",
      "Requirement already satisfied: cytoolz<0.10,>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (0.9.0.1)\n",
      "Requirement already satisfied: wrapt<1.11.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.10.11)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (4.25.0)\n",
      "Requirement already satisfied: six<2.0.0,>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from thinc<6.11.0,>=6.10.3->spacy) (1.11.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2018.8.24)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.22)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.6)\n",
      "Requirement already satisfied: toolz>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy) (0.9.0)\n",
      "Collecting fr_core_news_sm==2.0.0 from https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz#egg=fr_core_news_sm==2.0.0\n",
      "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-2.0.0/fr_core_news_sm-2.0.0.tar.gz (39.8MB)\n",
      "\u001b[K    100% |████████████████████████████████| 39.8MB 1.0MB/s \n",
      "\u001b[?25hInstalling collected packages: fr-core-news-sm\n",
      "  Running setup.py install for fr-core-news-sm ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fr-core-news-sm-2.0.0\n",
      "\n",
      "\u001b[93m    Linking successful\u001b[0m\n",
      "    /usr/local/lib/python3.6/dist-packages/fr_core_news_sm -->\n",
      "    /usr/local/lib/python3.6/dist-packages/spacy/data/fr\n",
      "\n",
      "    You can now load the model via spacy.load('fr')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import Keras library\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import LSTM, Input, Bidirectional\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.metrics import categorical_accuracy\n",
    "\n",
    "#import spacy, and spacyfrench model\n",
    "# spacy is used to work on text\n",
    "! pip install spacy\n",
    "import spacy\n",
    "!python -m spacy download fr\n",
    "nlp = spacy.load('fr')\n",
    "\n",
    "#import other libraries\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import codecs\n",
    "import collections\n",
    "from six.moves import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "utepWPVY7mee"
   },
   "outputs": [],
   "source": [
    "#define parameters used in the tutorial\n",
    "data_dir = '../data'# data directory containing input.txt\n",
    "save_dir = '../out' # directory to store models\n",
    "seq_length = 30 # sequence length\n",
    "sequences_step = 1 #step to create sequences\n",
    "vocab_file = os.path.join(save_dir,  \"words_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I0ddf0gL-0Sm"
   },
   "outputs": [],
   "source": [
    "def create_wordlist(doc):\n",
    "    wl = []\n",
    "    for word in doc:\n",
    "        if word.text not in (\"\\n\",\"\\n\\n\",'\\u2009','\\xa0'):\n",
    "            wl.append(word.text.lower())\n",
    "    return wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyYvU6Fp-7xF"
   },
   "outputs": [],
   "source": [
    "wordlist = []\n",
    "\n",
    "for file_name in file_list:\n",
    "    input_file = os.path.join(data_dir, file_name)\n",
    "    #read data\n",
    "    with codecs.open(input_file, \"r\") as f:\n",
    "        data = f.read()\n",
    "    #create sentences\n",
    "    doc = nlp(data)\n",
    "    wl = create_wordlist(doc)\n",
    "    wordlist = wordlist + wl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 997,
     "status": "ok",
     "timestamp": 1535999032005,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "EplWZoO2ANe5",
    "outputId": "0d9c9326-c6cc-4453-c87b-e4a099b6b0b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mara', 'est', 'revenue', 'dans', 'la', 'caverne', 'et', 's’', 'est', 'faufilée', 'dans', 'la', 'partie', 'transformée', 'en', 'hôpital', 'de', 'campagne', '.', 'elle']\n",
      "Gen RAM Free: 11.6 GB  | Proc size: 1.6 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "print(wordlist[:20])\n",
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 928,
     "status": "ok",
     "timestamp": 1535999037420,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "9zZ2KZ-nAdIR",
    "outputId": "c26d64ba-1c7b-468c-c5b3-82532a47a47e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47213"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wordlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TPiFoIulApEV"
   },
   "outputs": [],
   "source": [
    "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1535999041587,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "VNPJtUkKAglx",
    "outputId": "cc8a7335-6990-421d-e4f5-e012720e726e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab size:  5749\n"
     ]
    }
   ],
   "source": [
    "# count the number of words\n",
    "word_counts = collections.Counter(wordlist)\n",
    "\n",
    "# Mapping from index to word : that's the vocabulary\n",
    "vocabulary_inv = [x[0] for x in word_counts.most_common()]\n",
    "vocabulary_inv = list(sorted(vocabulary_inv))\n",
    "\n",
    "# Mapping from word to index\n",
    "vocab = {x: i for i, x in enumerate(vocabulary_inv)}\n",
    "words = [x[0] for x in word_counts.most_common()]\n",
    "\n",
    "#size of the vocabulary\n",
    "vocab_size = len(words)\n",
    "print(\"vocab size: \", vocab_size)\n",
    "\n",
    "#save the words and vocabulary\n",
    "with open(os.path.join(vocab_file), 'wb') as f:\n",
    "    cPickle.dump((words, vocab, vocabulary_inv), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 820,
     "status": "ok",
     "timestamp": 1535999044473,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "O5u7eQQeTl4F",
    "outputId": "8a8e74b2-f70e-4eec-d66f-698e2a2843c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 11.6 GB  | Proc size: 1.6 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 883,
     "status": "ok",
     "timestamp": 1535999047477,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "ErlZwiqMAjFZ",
    "outputId": "00f195f1-06cf-4c5f-ae63-619db859e750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 47183\n"
     ]
    }
   ],
   "source": [
    "#create sequences\n",
    "sequences = []\n",
    "next_words = []\n",
    "for i in range(0, len(wordlist) - seq_length, sequences_step):\n",
    "    sequences.append(wordlist[i: i + seq_length])\n",
    "    next_words.append(wordlist[i + seq_length])\n",
    "\n",
    "print('nb sequences:', len(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKiLZrTSA0EY"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sequences), seq_length, vocab_size), dtype=np.bool)\n",
    "y = np.zeros((len(sequences), vocab_size), dtype=np.bool)\n",
    "for i, sentence in enumerate(sequences):\n",
    "    for t, word in enumerate(sentence):\n",
    "        X[i, t, vocab[word]] = 1\n",
    "    y[i, vocab[next_words[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 865,
     "status": "ok",
     "timestamp": 1535999061916,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "dEmaCwMTTq_Y",
    "outputId": "7b95ac88-8858-4ae7-b708-b400613db994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 3.5 GB  | Proc size: 9.8 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iMdjkz59A3so"
   },
   "outputs": [],
   "source": [
    "def bidirectional_lstm_model(seq_length, vocab_size):\n",
    "    print('Build LSTM model.')\n",
    "    model = Sequential()\n",
    "    model.add(Bidirectional(LSTM(rnn_size, activation=\"relu\"),input_shape=(seq_length, vocab_size)))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Dense(vocab_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    callbacks=[EarlyStopping(patience=2, monitor='val_loss')]\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=[categorical_accuracy])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Wy8TBGvFNHz"
   },
   "outputs": [],
   "source": [
    "rnn_size = 256 # size of RNN\n",
    "batch_size = 32 # minibatch size\n",
    "seq_length = 30 # sequence length\n",
    "num_epochs = 2 # number of epochs\n",
    "learning_rate = 0.001 #learning rate\n",
    "sequences_step = 1 #step to create sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1754,
     "status": "ok",
     "timestamp": 1535999073211,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "Ke7nIM1QFPGj",
    "outputId": "263bfc7a-ea2e-4ba5-f662-3c0b20ecbe76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build LSTM model.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "bidirectional_1 (Bidirection (None, 512)               12300288  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5749)              2949237   \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 5749)              0         \n",
      "=================================================================\n",
      "Total params: 15,249,525\n",
      "Trainable params: 15,249,525\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "md = bidirectional_lstm_model(seq_length, vocab_size)\n",
    "md.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 633631,
     "status": "ok",
     "timestamp": 1536000003282,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "zEgb8zlvFQ2r",
    "outputId": "cfc55e10-a3a0-4808-b8b5-e6165de7e6a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46711 samples, validate on 472 samples\n",
      "Epoch 1/2\n",
      "46711/46711 [==============================] - 431s 9ms/step - loss: 6.3761 - categorical_accuracy: 0.0475 - val_loss: 5.9715 - val_categorical_accuracy: 0.0530\n",
      "Epoch 2/2\n",
      "46711/46711 [==============================] - 429s 9ms/step - loss: 5.9608 - categorical_accuracy: 0.0618 - val_loss: 5.7778 - val_categorical_accuracy: 0.0805\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "callbacks=[EarlyStopping(patience=4, monitor='val_loss'),\n",
    "           ModelCheckpoint(filepath=save_dir + \"/\" + 'my_model_gen_sentences_lstm.{epoch:02d}-{val_loss:.2f}.hdf5',\\\n",
    "                           monitor='val_loss', verbose=0, mode='auto', period=2)]\n",
    "history = md.fit(X, y,\n",
    "                 batch_size=batch_size,\n",
    "                 shuffle=True,\n",
    "                 epochs=num_epochs,\n",
    "                 callbacks=callbacks,\n",
    "                 validation_split=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1536000016474,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "yE1tsNcrFTi0",
    "outputId": "723b5207-e132-4ae9-9fe5-59514dd1d518"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 3.3 GB  | Proc size: 10.1 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HuIRDatLPl_Y"
   },
   "outputs": [],
   "source": [
    "#save the model\n",
    "md.save(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 807,
     "status": "ok",
     "timestamp": 1536000025005,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "_R60CwWKqj6I",
    "outputId": "769f2231-e2e2-4abb-cf99-2f3a4539bb5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading vocabulary...\n"
     ]
    }
   ],
   "source": [
    "#load vocabulary\n",
    "print(\"loading vocabulary...\")\n",
    "vocab_file = os.path.join(save_dir, \"words_vocab.pkl\")\n",
    "\n",
    "with open(os.path.join(save_dir, 'words_vocab.pkl'), 'rb') as f:\n",
    "        words, vocab, vocabulary_inv = cPickle.load(f)\n",
    "\n",
    "vocab_size = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 771,
     "status": "ok",
     "timestamp": 1536000030881,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "n2yuSNT_quet",
    "outputId": "bb84c039-8cc5-4896-d8d3-c35ea0982f5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 3.1 GB  | Proc size: 10.4 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5394,
     "status": "ok",
     "timestamp": 1536000039559,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "kNNr3idWq6Ok",
    "outputId": "5b6a2dc0-361b-430e-c884-2382125d72d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model...\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "# load the model\n",
    "print(\"loading model...\")\n",
    "model = load_model(save_dir + \"/\" + 'my_model_gen_sentences_lstm.final.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1536000045557,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "GSgmFoeiq-aM",
    "outputId": "a934e234-0840-4c80-e91c-2139f8eb20b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gen RAM Free: 2.6 GB  | Proc size: 10.7 GB\n",
      "GPU RAM Free: 11439MB | Used: 0MB | Util   0% | Total 11439MB\n"
     ]
    }
   ],
   "source": [
    "printm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WvMDg1J_vK5Z"
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 745,
     "status": "ok",
     "timestamp": 1536000082994,
     "user": {
      "displayName": "rayhan ML",
      "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
      "userId": "105722943493424036629"
     },
     "user_tz": -360
    },
    "id": "L9OmTwcOvQkA",
    "outputId": "cf8993f8-1486-4756-e430-ba7a0f7b188b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating text with the following seed: \"a a a a a a a a a a a a a a a a a a nolan avance sur le chemin de pierre et grimpe les marches .\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initiate sentences\n",
    "seed_sentences = \"nolan avance sur le chemin de pierre et grimpe les marches .\"\n",
    "generated = ''\n",
    "sentence = []\n",
    "for i in range (seq_length):\n",
    "    sentence.append(\"a\")\n",
    "\n",
    "seed = seed_sentences.split()\n",
    "\n",
    "for i in range(len(seed)):\n",
    "    sentence[seq_length-i-1]=seed[len(seed)-i-1]\n",
    "\n",
    "generated += ' '.join(sentence)\n",
    "print('Generating text with the following seed: \"' + ' '.join(sentence) + '\"')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zgSCCMoQvUC4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Text Generation.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
